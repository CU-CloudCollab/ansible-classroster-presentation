# USE ec2_remote_facts first to start any stopped instances, otherwise
# this automatically creates another instance with same name

- name: Provision Web Instance {{ instance_name }}
  ec2:
    key_name: "{{ aws_priv_key }}"
    group_id: ['{{ sg_web_public.group_id }}', '{{ sg_ssh_campus.group_id }}', '{{ aws_sg_default }}']
    instance_tags:
      Name: "{{ instance_name }}"
      Environment: "{{ instance_environment }}"
    count_tag:
      Name: "{{ instance_name }}"
      Environment: "{{ instance_environment }}"
    exact_count: "{{ instance_count }}"
    instance_type: "{{ instance_type|default('t2.micro')}}"
    assign_public_ip: no
    image: "{{ aws_ami_id }}"
    region: "{{ aws_region }}"
    # do not assign profile during demo
    #instance_profile_name: "Webserver"
    wait: yes
    vpc_subnet_id: "{{ vpc_subnet_id|default(aws_subnet_pri_public) }}"
    zone: "{{ zone|default(aws_zone_pri) }}"
    volumes:
      - device_name: /dev/xvda
        volume_type: gp2
        volume_size: "{{ root_ebs_size|default('8')}}"
        delete_on_termination: true
  register: ec2_web

# - debug: var=ec2_web

# NOTE:
# ec2_web.instances only includes newly created
# ec2_web.tagged_instances include all instances

- name: Get volume info for instances above
  ec2_vol:
    region: "{{ aws_region }}"
    instance: "{{ item.id }}"
    state: list
  with_items: "{{ ec2_web.tagged_instances }}"
  register: ec2_web_vol

# - debug: var=ec2_web_vol

- name: Tag root volumes
  ec2_tag:
    region: "{{ aws_region }}"
    resource: "{{ lookup('ec2_vol_find_volume_id', item.volumes, '/dev/xvda') }}"
    state: present
    tags:
      Name: "{{ instance_name }}-root"
      Environment: "{{ instance_environment }}"
  with_items: "{{ ec2_web_vol.results }}"

# - debug: var=web_filesystems

- name: Create EBS volume(s) on {{ instance_name }}
  ec2_vol:
    volume_size: "{{ item[1].volume_size }}"
    device_name: "{{ item[1].device }}"
    instance: "{{ item[0].id }}"
    region: "{{ aws_region }}"
    state: present
    volume_type: gp2
  register: ec2_webdata_vols
  with_nested:
    - "{{ ec2_web.instances }}"
    - "{{ web_filesystems }}"

# - debug: var=ec2_webdata_vols

- name: Get volume info for existing instances
  ec2_vol:
    region: "{{ aws_region }}"
    instance: "{{ item.id }}"
    state: list
  with_items: "{{ ec2_web.tagged_instances }}"
  register: ec2_webdata_vols

# - debug: var=ec2_webdata_vols

- name: Tag our additional volumes
  ec2_tag:
    region: "{{ aws_region }}"
    resource: "{{ lookup('ec2_vol_find_volume_id', item[0].volumes, item[1].device) }}"
    state: present
    tags:
      Name: "{{ instance_name }}-{{ item[1].volume_name }}"
      Environment: "{{ instance_environment }}"
  with_nested:
    - "{{ ec2_webdata_vols.results }}"
    - "{{ web_filesystems }}"


# this doesn't make sense if if instance count above is more than 1 since we'll overwrite
- name: Create R53 record for public ip
  route53:
    command: create
    zone: "{{ aws_dns_zone }}"
    record: "{{ instance_name}}.{{ aws_dns_zone }}"
    type: A
    ttl: 60
    overwrite: true
    value: "{{ item.public_ip }}"
  with_items: "{{ ec2_web.tagged_instances }}"
  when: (instance_count == 1) and (create_public_dns_record == true) and (create_private_dns_record == false)

- name: Create R53 record for private IP
  route53:
    command: create
    zone: "{{ aws_dns_zone }}"
    record: "{{ instance_name}}.{{ aws_dns_zone }}"
    type: A
    ttl: 60
    overwrite: true
    value: "{{ item.private_ip }}"
  with_items: "{{ ec2_web.tagged_instances }} "
  when: (instance_count == 1) and (create_public_dns_record == false) and (create_private_dns_record == true)

# since we expect to config later, let's wait until SSH is avail
- name: Wait for SSH to come up
  wait_for:
    # for demo, using public_ip
    host: "{{ item.public_ip }}"
    port: 22
    delay: 30
    timeout: 320
    state: started
  with_items: "{{ ec2_web.instances }}"
